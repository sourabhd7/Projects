# -*- coding: utf-8 -*-
"""Drone.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eHHaVDwenfyPy2i9NuBW_TqICNYFsozr
"""

import numpy as np 
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms as T
import torchvision
import torch.nn.functional as F
from torch.autograd import Variable

from PIL import Image
import cv2
import albumentations as A

import time
import os
from tqdm.notebook import tqdm

!pip install -q segmentation-models-pytorch
!pip install -q torchsummary

from torchsummary import summary
import segmentation_models_pytorch as smp

from google.colab import drive
drive.mount('/content/drive')

"""##Preprocessing"""

IMAGE_PATH = '/content/drive/MyDrive/Deep Learning Project/dataset/semantic_drone_dataset/original_images/'
MASK_PATH = '/content/drive/MyDrive/Deep Learning Project/dataset/semantic_drone_dataset/label_images_semantic/'

numOfClasses = 23 

def Create_dataset():
    name = []
    for dirname, _, filenames in os.walk(IMAGE_PATH):
        for filename in filenames:
            name.append(filename.split('.')[0])
    
    return pd.DataFrame({'id': name}, index = np.arange(0, len(name)))

data = Create_dataset()
print('Total Images: ', len(data))

#split data
X_trainval, X_test = train_test_split(data['id'].values, test_size=0.1, random_state=19)
X_train, X_val = train_test_split(X_trainval, test_size=0.15, random_state=19)

print('Training Size   : ', len(X_train))
print('Val Size     : ', len(X_val))
print('Testing Size    : ', len(X_test))

img = Image.open(IMAGE_PATH + data['id'][100] + '.jpg')
mask = Image.open(MASK_PATH + data['id'][100] + '.png')
print('Image Size', np.asarray(img).shape)
print('Mask Size', np.asarray(mask).shape)


plt.imshow(img)
plt.imshow(mask, alpha=0.6)
plt.title('Images with Mask Appplied')
plt.show()

"""##Dataset"""

class DroneDataset(Dataset):
    
    def __init__(self, img_path, mask_path, X, mean, std, transform=None, patch=False):
        self.img_path = img_path
        self.mask_path = mask_path
        self.X = X
        self.transform = transform
        self.patches = patch
        self.mean = mean
        self.std = std
        
    def __len__(self):
        return len(self.X)
    
    def __getitem__(self, idx):
        img = cv2.imread(self.img_path + self.X[idx] + '.jpg')
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        mask = cv2.imread(self.mask_path + self.X[idx] + '.png', cv2.IMREAD_GRAYSCALE)
        
        if self.transform is not None:
            aug = self.transform(image=img, mask=mask)
            img = Image.fromarray(aug['image'])
            mask = aug['mask']
        
        if self.transform is None:
            img = Image.fromarray(img)
        
        t = T.Compose([T.ToTensor(), T.Normalize(self.mean, self.std)])
        img = t(img)
        mask = torch.from_numpy(mask).long()
        
        if self.patches:
            img, mask = self.tiles(img, mask)
            
        return img, mask
    
    def tiles(self, img, mask):

        patch_img = img.unfold(1, 512, 512).unfold(2, 768, 768) 
        patch_img  = patch_img.contiguous().view(3,-1, 512, 768) 
        patch_img = patch_img.permute(1,0,2,3)
        
        patch_mask = mask.unfold(0, 512, 512).unfold(1, 768, 768)
        patch_mask = patch_mask.contiguous().view(-1, 512, 768)
        
        return patch_img, patch_mask

mean=[0.485, 0.456, 0.406]
std=[0.229, 0.224, 0.225]

t_train = A.Compose([A.Resize(704, 1056, interpolation=cv2.INTER_NEAREST), A.HorizontalFlip(), A.VerticalFlip(), 
                     A.GridDistortion(p=0.2), A.RandomBrightnessContrast((0,0.5),(0,0.5)),
                     A.GaussNoise()])

t_val = A.Compose([A.Resize(704, 1056, interpolation=cv2.INTER_NEAREST), A.HorizontalFlip(),
                   A.GridDistortion(p=0.2)])

#datasets
train_set = DroneDataset(IMAGE_PATH, MASK_PATH, X_train, mean, std, t_train, patch=False)
val_set = DroneDataset(IMAGE_PATH, MASK_PATH, X_val, mean, std, t_val, patch=False)

#dataloader
batch_size= 3 

train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True)

"""#Model"""

model = smp.Unet('mobilenet_v2', encoder_weights='imagenet', classes=23, activation=None, encoder_depth=5, decoder_channels=[256, 128, 64, 32, 16])

"""#Training"""

def pixel_accuracy(results, mask):
    with torch.no_grad():
        results = torch.argmax(F.softmax(results, dim=1), dim=1)
        correct = torch.eq(results, mask).int()
        accuracy = float(correct.sum()) / float(correct.numel())
    return accuracy

def mIoU(mask_pred, mask, smooth=1e-10, numOfClasses=23):
    with torch.no_grad():
        mask_pred = F.softmax(mask_pred, dim=1)
        mask_pred = torch.argmax(mask_pred, dim=1)
        mask_pred = mask_pred.contiguous().view(-1)
        mask = mask.contiguous().view(-1)

        iou_per_class = []
        for clas in range(0, numOfClasses): #loop per pixel class
            true_class = mask_pred == clas
            true_label = mask == clas

            if true_label.long().sum().item() == 0: #no exist label in this loop
                iou_per_class.append(np.nan)
            else:
                intersect = torch.logical_and(true_class, true_label).sum().float().item()
                union = torch.logical_or(true_class, true_label).sum().float().item()

                iou = (intersect + smooth) / (union +smooth)
                iou_per_class.append(iou)
        return np.nanmean(iou_per_class)

def get_lr(optimizer):
    for param_group in optimizer.param_groups:
        return param_group['lr']

def fit(epochs, model, train_loader, val_loader, criterion, optimizer, scheduler, patch=False):
    torch.cuda.empty_cache()
    train_los = []
    test_los = []
    val_IoU = []; val_acc = []
    train_IoU = []; train_acc = []
    lrs = []
    min_loss = np.inf
    decrease = 1 ; not_improve=0

    model.to(device)
    fit_time = time.time()
    for e in range(epochs):
        since = time.time()
        running_loss = 0
        iou_score = 0
        accuracy = 0
        #train_loop
        model.train()
        for i, data in enumerate(tqdm(train_loader)):
            #training_phase
            img_tile, mask_tile = data
            if patch:
                bs, n_tiles, c, h, w = img_tile.size()

                img_tile = img_tile.view(-1,c, h, w)
                mask_tile = mask_tile.view(-1, h, w)
            
            image = img_tile.to(device); mask = mask_tile.to(device);
            #Forward
            results = model(image)
            loss = criterion(results, mask)
            #Evaluation_Metrics
            iou_score += mIoU(results, mask)
            accuracy += pixel_accuracy(results, mask)
            #backward
            loss.backward()
            optimizer.step()          
            optimizer.zero_grad()
        
            lrs.append(get_lr(optimizer))
            scheduler.step() 
            running_loss += loss.item()
            
        else:
            model.eval()
            test_loss = 0
            test_accuracy = 0
            val_IoU_score = 0
            #Loop
            with torch.no_grad():
                for i, data in enumerate(tqdm(val_loader)):
                    #reshape from single image to nine patches
                    img_tile, mask_tile = data

                    if patch:
                        bs, n_tiles, c, h, w = img_tile.size()

                        img_tile = img_tile.view(-1,c, h, w)
                        mask_tile = mask_tile.view(-1, h, w)
                    
                    image = img_tile.to(device); mask = mask_tile.to(device);
                    results = model(image)
                    #Evaluation_Metrics
                    val_IoU_score +=  mIoU(results, mask)
                    test_accuracy += pixel_accuracy(results, mask)
                    #Los
                    loss = criterion(results, mask)                                  
                    test_loss += loss.item()
            
            #Mean Calculation for each batch
            train_los.append(running_loss/len(train_loader))
            test_los.append(test_loss/len(val_loader))


            if min_loss > (test_loss/len(val_loader)):
                print('Loss Decreasing.. {:.3f} >> {:.3f} '.format(min_loss, (test_loss/len(val_loader))))
                min_loss = (test_loss/len(val_loader))
                decrease += 1
                if decrease % 5 == 0:
                    print('saving model...')
                    torch.save(model, 'Unet-Mobilenet_v2_mIoU-{:.3f}.pt'.format(val_IoU_score/len(val_loader)))
                    

            if (test_loss/len(val_loader)) > min_loss:
                not_improve += 1
                min_loss = (test_loss/len(val_loader))
                print(f'Loss Not Decrease for {not_improve} time')
                if not_improve == 7:
                    print('Loss not decrease for 7 times, Stop Training')
                    break
            
            #iou
            val_IoU.append(val_IoU_score/len(val_loader))
            train_IoU.append(iou_score/len(train_loader))
            train_acc.append(accuracy/len(train_loader))
            val_acc.append(test_accuracy/ len(val_loader))
            print("Epoch:{}/{}..".format(e+1, epochs),
                  "Train Loss: {:.3f}..".format(running_loss/len(train_loader)),
                  "Val Loss: {:.3f}..".format(test_loss/len(val_loader)),
                  "Train mIoU:{:.3f}..".format(iou_score/len(train_loader)),
                  "Val mIoU: {:.3f}..".format(val_IoU_score/len(val_loader)),
                  "Train Acc:{:.3f}..".format(accuracy/len(train_loader)),
                  "Val Acc:{:.3f}..".format(test_accuracy/len(val_loader)),
                  "Time: {:.2f}m".format((time.time()-since)/60))
        
    history = {'train_loss' : train_los, 'val_loss': test_los,
               'train_miou' :train_IoU, 'val_miou':val_IoU,
               'train_acc' :train_acc, 'val_acc':val_acc,
               'lrs': lrs}
    print('Total Time: {:.2f} m' .format((time.time()- fit_time)/60))
    return history

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

max_lr = 1e-3
epoch = 5
weight_decay = 1e-4

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.AdamW(model.parameters(), lr=max_lr, weight_decay=weight_decay)
sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epoch,
                                            steps_per_epoch=len(train_loader))

history = fit(epoch, model, train_loader, val_loader, criterion, optimizer, sched)

torch.save(model, 'Unet-Mobilenet.pt')

def plot_acc(history):
    plt.plot(history['train_acc'], label='train_accuracy', marker='*')
    plt.plot(history['val_acc'], label='val_accuracy',  marker='*')
    plt.title('Accuracy per Epoch'); plt.ylabel('Accuracy')
    plt.xlabel('Epoch')
    plt.legend(), plt.grid()
    plt.show()

plot_acc(history)

"""#Evaluation"""

class DroneTestDataset(Dataset):
    
    def __init__(self, img_path, mask_path, X, transform=None):
        self.img_path = img_path
        self.mask_path = mask_path
        self.X = X
        self.transform = transform
      
    def __len__(self):
        return len(self.X)
    
    def __getitem__(self, idx):
        img = cv2.imread(self.img_path + self.X[idx] + '.jpg')
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        mask = cv2.imread(self.mask_path + self.X[idx] + '.png', cv2.IMREAD_GRAYSCALE)
        
        if self.transform is not None:
            aug = self.transform(image=img, mask=mask)
            img = Image.fromarray(aug['image'])
            mask = aug['mask']
        
        if self.transform is None:
            img = Image.fromarray(img)
        
        mask = torch.from_numpy(mask).long()
        
        return img, mask


t_test = A.Resize(768, 1152, interpolation=cv2.INTER_NEAREST)
test_set = DroneTestDataset(IMAGE_PATH, MASK_PATH, X_test, transform=t_test)

def predict_image_mask_miou(model, image, mask, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):
    model.eval()
    t = T.Compose([T.ToTensor(), T.Normalize(mean, std)])
    image = t(image)
    model.to(device); image=image.to(device)
    mask = mask.to(device)
    with torch.no_grad():
        
        image = image.unsqueeze(0)
        mask = mask.unsqueeze(0)
        
        results = model(image)
        score = mIoU(results, mask)
        masked = torch.argmax(results, dim=1)
        masked = masked.cpu().squeeze(0)
    return masked, score

def predict_image_mask_pixel(model, image, mask, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):
    model.eval()
    t = T.Compose([T.ToTensor(), T.Normalize(mean, std)])
    image = t(image)
    model.to(device); image=image.to(device)
    mask = mask.to(device)
    with torch.no_grad():
        
        image = image.unsqueeze(0)
        mask = mask.unsqueeze(0)
        
        results = model(image)
        acc = pixel_accuracy(results, mask)
        masked = torch.argmax(results, dim=1)
        masked = masked.cpu().squeeze(0)
    return masked, acc

image, mask = test_set[4]
mask_pred, score = predict_image_mask_miou(model, image, mask)

fig, (original_pic, ground_truth, output_image) = plt.subplots(1,3, figsize=(20,10))
original_pic.imshow(image)
original_pic.set_title('Original Image');

ground_truth.imshow(mask)
ground_truth.set_title('Ground Truth')
ground_truth.set_axis_off()

output_image.imshow(mask_pred)
output_image.set_title('Output |  {:.3f}'.format(score))
output_image.set_axis_off()

image2, mask2 = test_set[5]
mask_pred2, score2 = predict_image_mask_miou(model, image2, mask2)

fig, (original_pic, ground_truth, output_image) = plt.subplots(1,3, figsize=(20,10))
original_pic.imshow(image2)
original_pic.set_title('Original Image');

ground_truth.imshow(mask2)
ground_truth.set_title('Ground Truth')
ground_truth.set_axis_off()

output_image.imshow(mask_pred2)
output_image.set_title('Output | mIoU {:.3f}'.format(score2))
output_image.set_axis_off()

image3, mask3 = test_set[7]
mask_pred3, score3 = predict_image_mask_miou(model, image3, mask3)

fig, (original_pic, ground_truth, output_image) = plt.subplots(1,3, figsize=(20,10))
original_pic.imshow(image3)
original_pic.set_title('Original Image');

ground_truth.imshow(mask3)
ground_truth.set_title('Ground Truth')
ground_truth.set_axis_off()

output_image.imshow(mask_pred3)
output_image.set_title('Output | mIoU {:.3f}'.format(score3))
output_image.set_axis_off()

"""#Google map image prediction"""

def predict_image(model, image, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):
    model.eval()
    t = T.Compose([T.ToTensor(), T.Normalize(mean, std)])
    image = t(image)
    model.to(device); image=image.to(device)
    with torch.no_grad():
        
        image = image.unsqueeze(0)
        
        
        results = model(image)
        masked = torch.argmax(results, dim=1)
        masked = masked.cpu().squeeze(0)
    return masked

image_map= Image.open('predict_image1.jpg')
mask_pred_map = predict_image(model, image_map)
plt.imshow(mask_pred_map)

image_map2= Image.open('predict_image2.JPG')
mask_pred_map2 = predict_image(model, image_map2)
plt.imshow(mask_pred_map2)